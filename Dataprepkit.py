# -*- coding: utf-8 -*-
"""data_processor.py.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OhGh-290z4zHRUh2mC1--4v4fGKDxSyn
"""

# The DataProcessor Class

# Introduction

# The DataProcessor class is a powerful tool for data preprocessing and analysis. It provides a variety of methods for loading, processing, and analyzing datasets, In this example notebook, we'll demonstrate how to use the `DataProcessor` class to perform basic data analysis, handle missing values, encode categorical data, and save processed data.

# Let's get started!

# Importing the Class

# First, we need to import the `DataProcessor` class into our notebook.

from data_processor import DataProcessor

# Create an instance of the DataProcessor class

data_processor = DataProcessor()

#Using the DataProcessor Class

# Load the data using the load_data method of the DataProcessor instance

# Prompt the user to input the data path

data_path = data_processor.prompt_data_path()
print("Data path:", data_path)

# Read the data from the specified path

df = data_processor.read_data(data_path)

# Determine the data types of columns

data_types = data_processor.determine_data_type(df)
print("Data types of columns:")
print(data_types)

# Perform basic analysis on the data

head, data_types, summary_statistics = data_processor.basic_analysis(df)

print("\nFirst 5 rows of the data:")
print(head)

print("\nData types of columns:")
print(data_types)

print("\nSummary statistics of the data:")
print(summary_statistics)

df

df.isnull().sum()

print(df.dtypes)

# Print out the data types of each column

print("Data Types of Each Column:")
print(df.dtypes)

# Perform basic analysis on the data

print("\nBasic Analysis:")
head, data_types, summary_statistics = data_processor.basic_analysis(df)
print("\nFirst 5 rows of the data:")
print(head)
print("\nData Types of Columns:")
print(data_types)
print("\nSummary Statistics:")
print(summary_statistics)

# Prompt the user to choose a strategy for handling missing values
print("Choose a strategy for handling missing values:")
print("1. Mean")
print("2. Median")
print("3. Mode")
print("4. Forward Fill (ffill)")
print("5. Backward Fill (bfill)")
strategy_choice = input("Enter the number corresponding to your chosen strategy: ")

# Mapping strategy number to the actual strategy
strategies = {
    '1': 'mean',
    '2': 'median',
    '3': 'mode',
    '4': 'ffill',
    '5': 'bfill'
}

# If the user enters an invalid strategy number, default to mean
chosen_strategy = strategies.get(strategy_choice, 'mean')

# Check for missing values before handling

print("Before handling missing values:")
print(df.isnull().sum())

# Handle missing values using the chosen strategy
# Assuming df is your DataFrame

df = data_processor.handle_missing_values(df)

# Check for missing values after handling

print("\nAfter handling missing values using the '{}' strategy:".format(chosen_strategy))
print(df.isnull().sum())

df.isnull().sum()

import pandas as pd
from sklearn import preprocessing

class DataProcessor:
    def __init__(self):
        pass

    def prompt_data_path(self):
        """Prompt user to input data path."""
        data_path = input("Please enter the path to your data file: ")
        return data_path

    def determine_data_type(self, df):
        """Determine data types of columns."""
        data_types = df.dtypes.to_dict()
        return data_types

    def read_data(self, file_path):
        """Read data from specified path."""
        df = pd.read_csv(file_path)
        return df

    def basic_analysis(self, df):
        """Perform basic analysis on data."""
        head = df.head()
        data_types = self.determine_data_type(df)
        summary_statistics = df.describe()
        return head, data_types, summary_statistics

    def handle_missing_values(self, df, strategy='mean'):
        """Handle missing values in the DataFrame."""
        if strategy == 'mean':
            new_data = df.fillna(df.mean())
        elif strategy == 'median':
            new_data = df.fillna(df.median())
        elif strategy == 'mode':
            new_data = df.fillna(df.mode().iloc[0])
        elif strategy == 'ffill':
            new_data = df.fillna(method='ffill')
        elif strategy == 'bfill':
            new_data = df.fillna(method='bfill')
        else:
            raise ValueError("Invalid filling strategy. Specify 'mean', 'median', 'mode', 'ffill', or 'bfill'.")
        return new_data

    def encode_categorical_data(self, df, columns):
        """Encode categorical data using one-hot encoding."""
        encoded_df = pd.get_dummies(df, columns=columns, drop_first=False)
        return encoded_df

    def label_encode_categorical_data(self, df, columns):
        """Label encode categorical data."""
        encoder = preprocessing.LabelEncoder()
        for column in columns:
            df[column] = encoder.fit_transform(df[column])
        return df

# Instantiate the DataProcessor class
data_processor = DataProcessor()

# Import the DataProcessor class
from data_processor import DataProcessor

# Instantiate the DataProcessor class
data_processor = DataProcessor()

# Step 1: Ask the user to input the data path
data_path = data_processor.prompt_data_path()

# Step 2: Read the data from the specified path
df = data_processor.read_data(data_path)

# Step 3: Perform basic analysis on the data
head, data_types, summary_statistics = data_processor.basic_analysis(df)

# Display the results of basic analysis
print("\nFirst 5 rows of the data:")
print(head)
print("\nData types of columns:")
print(data_types)
print("\nSummary statistics of numerical columns:")
print(summary_statistics)



# Step 5: Encode categorical data
encoded_df = data_processor.encode_categorical_data(df, columns=['Name'])

# Display the encoded DataFrame
print("\nEncoded DataFrame:")
print(encoded_df.head())

# Step 6: Save or display the processed data
# For example, you can save the processed data to a CSV file
encoded_df.to_csv('processed_data.csv', index=False)
print("\nProcessed data saved to 'processed_data.csv'")

# Alternatively, you can display the processed data
# print("\nProcessed data:")
# print(encoded_df)